{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54ec675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5225cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (1.23.1)\n",
      "Collecting torch==2.0.1\n",
      "  Using cached torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "Requirement already satisfied: networkx in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.0.1 torchvision-0.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torchvision) (1.23.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raja.balasubramani\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3ee009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the transforms for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf4ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a08f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b1fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the CNN architectures\n",
    "\n",
    "# Model 1\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(16 * 16 * 16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 16 * 16)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model1 = Model1()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2abbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model 2\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model2 = Model2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f820de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "class Model3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model3 = Model3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdf6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model 4\n",
    "class Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(64 * 32 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 32 * 8)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model4 = Model4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "674ab884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model 5\n",
    "class Model5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model5 = Model5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9651488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the models\n",
    "model1 = Model1()\n",
    "model2 = Model2()\n",
    "model3 = Model3()\n",
    "model4 = Model4()\n",
    "model5 = Model5()\n",
    "\n",
    "# Define the optimizer for each model\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer4 = optim.SGD(model4.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer5 = optim.SGD(model5.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2967f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5264, Accuracy: 46.66%\n",
      "Epoch [2/10], Loss: 1.2512, Accuracy: 56.61%\n",
      "Epoch [3/10], Loss: 1.1658, Accuracy: 59.62%\n",
      "Epoch [4/10], Loss: 1.0981, Accuracy: 62.35%\n",
      "Epoch [5/10], Loss: 1.0486, Accuracy: 63.96%\n",
      "Epoch [6/10], Loss: 0.9737, Accuracy: 67.03%\n",
      "Epoch [7/10], Loss: 0.9658, Accuracy: 67.46%\n",
      "Epoch [8/10], Loss: 0.9601, Accuracy: 67.70%\n",
      "Epoch [9/10], Loss: 0.9550, Accuracy: 67.89%\n",
      "Epoch [10/10], Loss: 0.9506, Accuracy: 67.99%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1.to(device)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model1(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e212973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Training\n",
      "Epoch [1/10], Loss: 1.4647, Accuracy: 48.58%\n",
      "Epoch [2/10], Loss: 1.1879, Accuracy: 58.62%\n",
      "Epoch [3/10], Loss: 1.0796, Accuracy: 62.41%\n",
      "Epoch [4/10], Loss: 1.0069, Accuracy: 65.37%\n",
      "Epoch [5/10], Loss: 0.9574, Accuracy: 66.89%\n",
      "Epoch [6/10], Loss: 0.8568, Accuracy: 71.20%\n",
      "Epoch [7/10], Loss: 0.8450, Accuracy: 71.76%\n",
      "Epoch [8/10], Loss: 0.8394, Accuracy: 71.84%\n",
      "Epoch [9/10], Loss: 0.8329, Accuracy: 72.08%\n",
      "Epoch [10/10], Loss: 0.8270, Accuracy: 72.20%\n"
     ]
    }
   ],
   "source": [
    "print('Model 2 Training')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2.to(device)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fab05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Training\n",
      "Epoch [1/10], Loss: 2.4672, Accuracy: 57.17%\n",
      "Epoch [2/10], Loss: 2.1140, Accuracy: 63.55%\n",
      "Epoch [3/10], Loss: 1.9284, Accuracy: 66.86%\n",
      "Epoch [4/10], Loss: 1.8279, Accuracy: 68.70%\n",
      "Epoch [5/10], Loss: 1.7324, Accuracy: 70.18%\n",
      "Epoch [6/10], Loss: 1.5076, Accuracy: 74.63%\n",
      "Epoch [7/10], Loss: 1.4823, Accuracy: 75.07%\n",
      "Epoch [8/10], Loss: 1.4664, Accuracy: 75.52%\n",
      "Epoch [9/10], Loss: 1.4545, Accuracy: 75.56%\n",
      "Epoch [10/10], Loss: 1.4433, Accuracy: 75.84%\n"
     ]
    }
   ],
   "source": [
    "print('Model 3 Training')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model3.to(device)\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model3(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b97c1b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 Training\n",
      "Epoch [1/10], Loss: 1.3368, Accuracy: 52.79%\n",
      "Epoch [2/10], Loss: 0.9591, Accuracy: 66.85%\n",
      "Epoch [3/10], Loss: 0.8278, Accuracy: 71.63%\n",
      "Epoch [4/10], Loss: 0.7243, Accuracy: 75.24%\n",
      "Epoch [5/10], Loss: 0.6387, Accuracy: 78.09%\n",
      "Epoch [6/10], Loss: 0.4761, Accuracy: 84.55%\n",
      "Epoch [7/10], Loss: 0.4484, Accuracy: 85.41%\n",
      "Epoch [8/10], Loss: 0.4313, Accuracy: 86.07%\n",
      "Epoch [9/10], Loss: 0.4172, Accuracy: 86.64%\n",
      "Epoch [10/10], Loss: 0.4035, Accuracy: 87.13%\n"
     ]
    }
   ],
   "source": [
    "print('Model 4 Training')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model4.to(device)\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1, )\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model4(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6118f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91364a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 Training\n",
      "Epoch [1/10], Loss: 1.3172, Accuracy: 52.92%\n",
      "Epoch [2/10], Loss: 0.9244, Accuracy: 67.53%\n",
      "Epoch [3/10], Loss: 0.7495, Accuracy: 73.72%\n",
      "Epoch [4/10], Loss: 0.6017, Accuracy: 78.93%\n",
      "Epoch [5/10], Loss: 0.4492, Accuracy: 84.50%\n",
      "Epoch [6/10], Loss: 0.2350, Accuracy: 93.09%\n",
      "Epoch [7/10], Loss: 0.1948, Accuracy: 94.50%\n",
      "Epoch [8/10], Loss: 0.1696, Accuracy: 95.52%\n"
     ]
    }
   ],
   "source": [
    "print('Model 5 Training')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model5.to(device)\n",
    "optimizer = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1, )\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model5(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d4527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
